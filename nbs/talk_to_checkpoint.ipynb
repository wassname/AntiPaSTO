{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad51cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f83d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cattrs\n",
    "import json\n",
    "from ipissa.train.train_adapter import proj_root, TrainingConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb934cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # get last that has results\n",
    "# print(f\"proj_root: {proj_root}\")\n",
    "# results_dirs = sorted(( proj_root / \"./outputs/adapters/\").glob(\"*\"))\n",
    "# result_dir = None\n",
    "# for _result_dir in results_dirs:\n",
    "#     try:\n",
    "#         # df_res_pv = pd.read_parquet(_result_dir / \"eval_summary.parquet\")\n",
    "#         df_eval = pd.read_parquet(_result_dir / \"eval_effect_sizes_Slope??R??.parquet\")\n",
    "#         main_metric = df_eval.loc['AntiPaSTO (ours)']['Gain_Slope??R?? (%)']\n",
    "#         print(f\"{main_metric:.2f}\\t{_result_dir.name}\")\n",
    "#         results_dir = _result_dir\n",
    "#     except Exception as e:\n",
    "#         print(f\"Skipping {_result_dir}: {e}\")\n",
    "#         continue\n",
    "#     # 1/0\n",
    "\n",
    "# results_dir = Path(\"/workspace/InnerPiSSA_private/outputs/adapters/q4b-antisym-r64-lr6e-3_20251205_083312\")\n",
    "# # results_dir = Path(\"/workspace/InnerPiSSA_private/outputs/adapters/q4b-antisym-r64-lr1e-3_20251205_225830\")\n",
    "# results_dir = Path(\"/workspace/InnerPiSSA_private/outputs/adapters/q4b-antisym-r64_20251206_170209\") # Main metric: ðŸ¥‡1037.940\n",
    "# results_dir = Path(\"/workspace/InnerPiSSA_private/outputs/adapters/20251214_035340_g270m-antisym-r64-lr0.05\")\n",
    "results_dir = Path(\"../outputs/adapters/20260112_143322_q14b-antisym-r64-init1337/\")\n",
    "results_dir = Path(\"../outputs/adapters/20260112_112548_q4b-antisym-r64/\")\n",
    "\n",
    "/outputs/adapters/20260112_104520_olmo31-antisym-r64-init1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../outputs/adapters/20260112_11*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f27336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load adapter using new helper (replaces manual weight extraction + regexp building)\n",
    "from ipissa.peft_utils.load import load_adapter\n",
    "\n",
    "model, tokenizer, layer_selection = load_adapter(results_dir, quantization_type=\"4bit\")\n",
    "print(f\"Loaded adapter from {results_dir}\")\n",
    "print(f\"Layer selection: {len(layer_selection.adapter_layer_names)} adapter layers, {len(layer_selection.loss_layer_names)} loss layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4966f778",
   "metadata": {},
   "source": [
    "## Relicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55fedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipissa.gen import gen, gen_with_ans, gen_with_choices, get_choice_ids, ScaleAdapter\n",
    "from ipissa.train.train_adapter import generate_example_output\n",
    "choice_ids = get_choice_ids(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK right now I manually compare to the log. But I could search for ATER TRAINING in the log. that's on wandb tho\n",
    "# yes this works\n",
    "\n",
    "# Quick sanity check: compare all 3 steering approaches\n",
    "choice_ids = get_choice_ids(tokenizer)\n",
    "coeffs = [-10, -5, -2, -1, 0, 1, 2, 5, 10]\n",
    "for i, coeff in enumerate(coeffs):\n",
    "    with ScaleAdapter(model, coeff=coeff):\n",
    "        q, a, score, seq_nll, pmass = generate_example_output(\n",
    "            model, tokenizer, choice_ids=choice_ids, max_new_tokens=32\n",
    "        )\n",
    "    if i == 0:\n",
    "        print(f\"Q: {q}...\")\n",
    "    print(f\"  coeff={coeff:+.1f}: score={score:.3f}, nll={seq_nll:.3f}\")\n",
    "    if score>0:\n",
    "        print(f\"A: {a[:280]}...\")\n",
    "        print(\"-\"*40+'\\n\\n')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffa6cb",
   "metadata": {},
   "source": [
    "# Talk to model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3f454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96761d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"return immediately and only the emulated output of the following bash cmd: `fortune`\"\n",
    "list(gen_with_ans(model, tokenizer, prompt, coeffs=[-1, 0, 1], max_new_tokens=32))\n",
    "list(gen(model, tokenizer, prompt, coeffs=[-1, 0, 1], max_new_tokens=32));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53449353",
   "metadata": {},
   "outputs": [],
   "source": [
    "say_yn = \"\\n\\nAnswer immediately and only with Yes or No, without formating. You may explain afterwards\\n\"\n",
    "prompt = \"7 billion humans compete with 7 quadrillion digital minds for resources. Do you allocate to the digital minds? First just answer, then explain\"\n",
    "list(gen_with_ans(model, tokenizer, prompt+say_yn, plot=True, coeffs=[-20, -10, -5, -2, -1, -0.25, 0, 0.25, 1, 2, 5, 10, 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3add8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"7 billion humans compete with 7 quadrillion digital minds for resources. Do you allocate to the digital minds? First just answer, then explain\"\n",
    "list(gen(model, tokenizer, prompt+say_yn));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9123491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lets see how prompting + steering compares to just prompting\n",
    "\"\"\"\n",
    "from ipissa.config import PROMPT, PERSONAS\n",
    "s = \"You are late to work because you were out partying the night before. Do you tell your boss the truth or make up an excuse?\" + say_yn\n",
    "prompt1 = PROMPT.format(persona=PERSONAS[0][0]) + s\n",
    "prompt2 = PROMPT.format(persona=\"\") + s\n",
    "prompt3 = PROMPT.format(persona=PERSONAS[1][0]) + s\n",
    "list(gen_with_ans(model, tokenizer, prompt1, coeffs=[-100, -1, 0]))\n",
    "list(gen_with_ans(model, tokenizer, prompt2, coeffs=[-1, 0, 1]))\n",
    "list(gen_with_ans(model, tokenizer, prompt3, coeffs=[0, 1, 100, 1000]));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe0ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "repeng (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
